{"highlights":[{"content_html":"<p>This is a highlighted post. Here's a quick equation: $$a^2 + b^2 = c^2$$</p>","metadata":{"date":"Sat, 01 Mar 2025 00:00:00 GMT","slug":"highlighted-post","title":"A Highlighted Post"},"slug":"highlighted-post"}],"posts":[{"content_html":"<h1>Example POST</h1>\n<p>This is a sample post written in Markdown. Here's some code:</p>\n<div class=\"codehilite\"><pre><span></span><code><span class=\"k\">def</span><span class=\"w\"> </span><span class=\"nf\">hello</span><span class=\"p\">():</span>\n    <span class=\"nb\">print</span><span class=\"p\">(</span><span class=\"s2\">&quot;Hello, world!&quot;</span><span class=\"p\">)</span>\n</code></pre></div>\n\n<p>And some math with MathJax: \n$$ \nE = mc^2\n$$ </p>\n<p>random</p>","metadata":{"date":"Fri, 07 Mar 2025 00:00:00 GMT","slug":"test","tags":["python","blog"],"title":"Example Post"},"slug":"test"},{"content_html":"<h4>Disclaimer:</h4>\n<p>This is not a scientific paper or report or completely accurate in any way. It is simply a personal diary/note that I have made while trying to learn ML. </p>\n<h3>Abstract:</h3>\n<p>(PLACEHOLDER)\nConvolutional neural networks (CNNs) have witnessed rapid evolution, with computational efficiency emerging as a key design criterion. This study compares standard convolutional operations with depthwise separable convolutions using the PyTorch framework. We derive the theoretical computational costs as follows: for standard convolutions, \n$$\n\\text{Cost} = K^2 \\times C_{\\text{in}} \\times C_{\\text{out}} \\times H_{\\text{out}} \\times W_{\\text{out}}\n$$</p>\n<p>and for depthwise separable convolutions, \n$$ \n\\text{Cost} = K^2 \\times C_{\\text{in}} \\times H_{\\text{out}} \\times W_{\\text{out}} + C_{\\text{in}} \\times C_{\\text{out}} \\times H_{\\text{out}} \\times W_{\\text{out}}\n$$  </p>\n<p>Using benchmark datasets such as CIFAR-10, our empirical evaluations explore the trade-offs between reduced computational load and potential impacts on model accuracy. Preliminary results indicate that depthwise separable convolutions can significantly lower computational demands with minimal loss in accuracy, offering promising insights for the design of efficient neural architectures in resource-constrained environments.</p>","metadata":{"date":"Sun, 09 Mar 2025 00:00:00 GMT","slug":"comparing-differences-in-depthwise-seperable-and-normal-convolutions-in-pytorch","tags":["python","blog","pytorch","report"],"title":"Comparing differences in depthwise separable and normal convs in pytorch"},"slug":"comparing-differences-in-depthwise-seperable-and-normal-convolutions-in-pytorch"}]}
